{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence similarity\n",
    "def sentence_similarity(sent1, sent2):\n",
    "\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "                similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "    print (similarity_matrix)\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def read_article(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(file_name)\n",
    "    \n",
    "     # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "    \n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "    \n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(5):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - Offcourse, output the summarize texr\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This report deals with my experiences and knowledgeâ€™s that I have earned through the internship program\n",
      "The company profile of Streams Tech and its culture are also briefly discussed here.I have presented different kinds of information in this report which I gathered during internship period and collected from any written document such as Internet or from another person\n",
      "Most of the information is collected from web sites, articles, Streams Tech employees and some journals\n",
      "Information included in this report are classified into two categories, primary data source and secondary date source.How a team works and the process of working as a team along with my role, being a part of successful team, experiences within a team are also summarized in this report\n",
      "How I have adapted myself with the company culture and technologies is also mentioned\n",
      "Especially through this report I try to reflect on my project involvements and my experience of working in real-life projects\n",
      "The report concludes by elaborating my technical and professional growth after experiencing the internship program[78].\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Indexes of top ranked_sentence order are  [(0.16666666666666663, ['This', 'report', 'deals', 'with', 'my', 'experiences', 'and', 'knowledgeâ€™s', 'that', 'I', 'have', 'earned', 'through', 'the', 'internship', 'program']), (0.16666666666666663, ['The', 'company', 'profile', 'of', 'Streams', 'Tech', 'and', 'its', 'culture', 'are', 'also', 'briefly', 'discussed', 'here.I', 'have', 'presented', 'different', 'kinds', 'of', 'information', 'in', 'this', 'report', 'which', 'I', 'gathered', 'during', 'internship', 'period', 'and', 'collected', 'from', 'any', 'written', 'document', 'such', 'as', 'Internet', 'or', 'from', 'another', 'person']), (0.16666666666666663, ['Most', 'of', 'the', 'information', 'is', 'collected', 'from', 'web', 'sites,', 'articles,', 'Streams', 'Tech', 'employees', 'and', 'some', 'journals']), (0.16666666666666663, ['Information', 'included', 'in', 'this', 'report', 'are', 'classified', 'into', 'two', 'categories,', 'primary', 'data', 'source', 'and', 'secondary', 'date', 'source.How', 'a', 'team', 'works', 'and', 'the', 'process', 'of', 'working', 'as', 'a', 'team', 'along', 'with', 'my', 'role,', 'being', 'a', 'part', 'of', 'successful', 'team,', 'experiences', 'within', 'a', 'team', 'are', 'also', 'summarized', 'in', 'this', 'report']), (0.16666666666666663, ['How', 'I', 'have', 'adapted', 'myself', 'with', 'the', 'company', 'culture', 'and', 'technologies', 'is', 'also', 'mentioned']), (0.16666666666666663, ['Especially', 'through', 'this', 'report', 'I', 'try', 'to', 'reflect', 'on', 'my', 'project', 'involvements', 'and', 'my', 'experience', 'of', 'working', 'in', 'real-life', 'projects'])]\n",
      "Summarize Text: \n",
      " This report deals with my experiences and knowledgeâ€™s that I have earned through the internship program. The company profile of Streams Tech and its culture are also briefly discussed here.I have presented different kinds of information in this report which I gathered during internship period and collected from any written document such as Internet or from another person. Most of the information is collected from web sites, articles, Streams Tech employees and some journals. Information included in this report are classified into two categories, primary data source and secondary date source.How a team works and the process of working as a team along with my role, being a part of successful team, experiences within a team are also summarized in this report. How I have adapted myself with the company culture and technologies is also mentioned\n"
     ]
    }
   ],
   "source": [
    "# Starting from Here\n",
    "generate_summary( \"input.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
